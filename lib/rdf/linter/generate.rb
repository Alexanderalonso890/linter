module RDF::Linter
  # Generate cooked vocabulary defs
  class Generate
    # Create JSON representation of classes and properties in a vocabulary
    # If the vocabulary definition is not located at `url` set it in `location`.
    #
    # Extracts class/property IRIs and labels for vocabulary terms from
    # OWL/RDFS description of vocabulary
    #
    # @param [RDF::URL] url
    # @param [String] prefix
    # @param [Hash{Symbol => Object}] options
    # @option options [RDF::URL] :location (nil)
    # @option options [IO] :io (STDOUT)
    # @option options [Symbol] :format
    def vocab_def(url, prefix, options = {})
      io = options[:io] || STDOUT
      location = options[:location] || url
      require 'json'
      require 'sparql'
      defs = {
        "Vocabularies" => {prefix => url},
        "Classes" => {},
        "Properties" => {},
        "Datatypes" => {},
      }
      repo = RDF::Repository.load(location, options)

      # Query to get relevant vocabulary information
      vocab_query = RDF::Query.new do
        pattern [:subject, RDF.type, :type]
        pattern [:subject, RDF::RDFS.label, :label], optional: true
        pattern [:subject, RDF::RDFS.subClassOf, :superClass], optional: true
        pattern [:subject, RDF::RDFS.domain, :domain], optional: true
        pattern [:subject, RDF::RDFS.range, :range], optional: true
        pattern [:subject, RDF::SCHEMA.domainIncludes, :domainIncludes], optional: true
        pattern [:subject, RDF::SCHEMA.rangeIncludes, :rangeIncludes], optional: true
      end
      repo.query(vocab_query) do |soln|
        section = case soln.type
        when RDF.Property then "Properties"
        when RDF::RDFS.Class then "Classes"
        when RDF::RDFS.Datatype then "Datatypes"
        else next
        end
        d = (defs[section][soln.subject] ||= {:vocab => prefix, :label => (soln[:label] || soln.subject.to_s.split(/[\/#]/).last)})
        soln.each do |name, value|
          (d[name] ||= []) << value unless [:subject, :type, :label].include?(name)
        end
      end

      defs.keys.each {|k| defs.delete(k) if defs[k].empty?}
      # Serialize definitions
      io.puts defs.to_json(
        :indent       => "  ",
        :space        => " ",
        :space_before => "",
        :object_nl    => "\n",
        :array_nl     => "\n"
      )
    end
    
    # Create native representation of vocabulary definitions from JSON files
    def cook_vocabularies(io = STDOUT)
      require 'json'
      defs = {
        "Vocabularies" => {},
        "Classes" => {},
        "Properties" => {},
        "Datatypes" => {},
      }
      Dir.glob(File.join(File.dirname(__FILE__), "*.json")).each do |file|
        File.open(file) do |f|
          STDERR.puts "load #{file}"
          v = JSON.load(f)
          v.each do |sect, hash|
            raise "unknown section #{sect}" unless defs.has_key?(sect)
            v[sect].each do |name, defn|
              raise "attempt to redefine #{sect} definition of #{name}" if defs[sect].has_key?(name)
              defs[sect][name] = defn
            end
          end
        end
      end

      # Perform limted entailment of superClass relationships
      $stderr.puts "Perform super-class entailement"
      defs["Classes"].each do |k, v|
        $stderr.write(".")
        v["superClass"] = entail_classes(k, defs)
      end
      $stderr.puts("")

      # Serialize definitions
      io.puts "# This file is automatically generated by #{__FILE__}"
      io.puts "module RDF::Linter::Parser"
      io.puts "  VOCAB_DEFS = " + defs.inspect
      io.puts "end"
    end

    private
    def entail_classes(cls, defs)
      (@entailed_classes ||= {})[cls] ||= begin
        super_classes = defs["Classes"].fetch(cls, {}).fetch("superClass", []).dup
        (super_classes +
        super_classes.map do |sc|
          entail_classes(sc, defs)
        end.flatten).uniq
      end
    end
  end
end